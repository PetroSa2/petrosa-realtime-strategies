name: CI Checks

on:
  pull_request:
    branches: [main, develop]

jobs:
  lint:
    name: Lint & Format Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Cache virtual environment
        uses: actions/cache@v4
        with:
          path: .venv
          key: ${{ runner.os }}-venv-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-venv-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run linting
        run: make lint

      - name: Run type check
        run: make type-check
        continue-on-error: true  # Allow type check failures initially

  test:
    name: Test & Coverage
    runs-on: ubuntu-latest
    env:
      OTEL_NO_AUTO_INIT: 1
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Cache virtual environment
        uses: actions/cache@v4
        with:
          path: .venv
          key: ${{ runner.os }}-venv-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-venv-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run tests with coverage
        timeout-minutes: 10
        run: make test

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          slug: PetroSa2/petrosa-realtime-strategies
          file: ./coverage.xml
          flags: unittests
          fail_ci_if_error: true

  test-quality:
    name: Test Quality Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout service code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Download check-test-assertions.py script
        run: |
          # Download via GitHub API and decode using Python to avoid encoding issues
          python3 << 'PYEOF'
          import base64
          import json
          import urllib.request
          import urllib.error
          
          url = "https://api.github.com/repos/PetroSa2/petrosa_k8s/contents/scripts/check-test-assertions.py"
          headers = {
              "Authorization": f"token ${{ secrets.GITHUB_TOKEN }}",
              "Accept": "application/vnd.github.v3+json"
          }
          
          req = urllib.request.Request(url, headers=headers)
          try:
              with urllib.request.urlopen(req) as response:
                  data = json.loads(response.read())
                  content = base64.b64decode(data['content']).decode('utf-8')
                  
                  with open('/tmp/check-test-assertions.py', 'w', encoding='utf-8') as f:
                      f.write(content)
                  
                  print("âœ… Script downloaded successfully")
          except Exception as e:
              print(f"âŒ Failed to download script: {e}")
              exit(1)
          PYEOF
          chmod +x /tmp/check-test-assertions.py
          # Verify the file is valid Python
          python3 -m py_compile /tmp/check-test-assertions.py || {
            echo "âŒ Downloaded file is not valid Python"
            exit 1
          }
          echo "âœ… Script verified"

      - name: Check test assertions
        run: |
          # Find all test files and check them
          TEST_FILES=$(find . -type f -name "test_*.py" -o -name "*_test.py" | grep -v ".venv" | grep -v "__pycache__" || true)
          if [ -z "$TEST_FILES" ]; then
            echo "âš ï¸  No test files found - skipping test quality check"
            exit 0
          fi
          echo "Found test files:"
          echo "$TEST_FILES" | sed 's/^/  - /'
          python /tmp/check-test-assertions.py $(echo "$TEST_FILES" | tr '\n' ' ')
          if [ $? -ne 0 ]; then
            echo "âŒ Tests without assertions detected"
            exit 1
          fi
          echo "âœ… All tests have assertions"

  security:
    name: Security Scan
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write  # Required for SARIF upload
      actions: read
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for secret detection

      - name: ðŸ” Run Gitleaks (Secret Detection)
        uses: gitleaks/gitleaks-action@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITLEAKS_LICENSE: ${{ secrets.GITLEAKS_LICENSE }}  # Optional - works without license in v1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: ðŸ Run Bandit (Python Security)
        run: |
          pip install bandit[toml]
          bandit -r . \
            --severity-level medium \
            --confidence-level medium \
            --format json \
            --output bandit-report.json \
            --exclude tests/ \
            || true
          echo "ðŸ“Š Bandit Results:"
          python -m json.tool bandit-report.json | head -30 || echo "No issues found"

      - name: ðŸ—‚ï¸ Run Trivy (Vulnerability Scanner)
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
          exit-code: '1'  # Fail if vulnerabilities found
          ignore-unfixed: true

      - name: Upload Trivy results
        uses: github/codeql-action/upload-sarif@v3
        if: always() && hashFiles('trivy-results.sarif') != ''
        with:
          sarif_file: 'trivy-results.sarif'
        # Note: Upload step will fail if permissions not granted, which will block PR

  documentation-standards:
    name: Documentation Standards Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Check for temporary documentation patterns
        run: |
          temp_docs=$(find docs/ -maxdepth 1 -type f -regex '.*_\(SUMMARY\|FIX\|COMPLETE\|STATUS\)\.md$' || true)
          if [ -n "$temp_docs" ]; then
            echo "âŒ Found temporary documentation in docs/ root:"
            echo "$temp_docs"
            echo ""
            echo "These files should be in docs/archive/ subdirectories"
            exit 1
          fi
          echo "âœ… Documentation standards check passed"

  pipeline:
    name: pipeline
    runs-on: ubuntu-latest
    needs: [lint, test, test-quality, security, documentation-standards]
    if: always()
    permissions:
      checks: write
      statuses: write
    steps:
      - name: Create pipeline status check
        uses: actions/github-script@v7
        with:
          script: |
            const conclusion = '${{ needs.lint.result }}' === 'success' && 
                              '${{ needs.test.result }}' === 'success' && 
                              '${{ needs.test-quality.result }}' === 'success' && 
                              '${{ needs.security.result }}' === 'success' && 
                              '${{ needs.documentation-standards.result }}' === 'success' 
                              ? 'success' : 'failure';
            
            await github.rest.checks.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              name: 'pipeline',
              head_sha: context.sha,
              status: 'completed',
              conclusion: conclusion,
              output: {
                title: conclusion === 'success' ? 'All checks passed' : 'Some checks failed',
                summary: conclusion === 'success' 
                  ? 'All CI checks passed successfully.'
                  : 'One or more CI checks failed. Please review the failed jobs.'
              }
            });
